buildscript {
    repositories {
        maven { url "https://plugins.gradle.org/m2/" }
        mavenCentral()
    }
    dependencies {
        classpath 'org.github.ngbinh.scalastyle:gradle-scalastyle-plugin_2.11:0.9.0'
    }
}

plugins {
    id 'com.commercehub.gradle.plugin.avro' version '0.8.0'
    id 'org.scoverage' version '2.3.0'
    id 'net.minecrell.licenser' version '0.4.1'
    id 'com.github.jk1.dependency-license-report' version '0.5.0'
    id 'com.github.johnrengelman.shadow' version '2.0.4'
}

allprojects {
    repositories {
        mavenCentral()
        jcenter()
    }
}

apply from: 'gradle/version-properties.gradle'

def allProjs = allprojects - project(':templates').subprojects
def subProjs = subprojects - project(':templates').subprojects

// distribute to all projects
ext.subProjs = subProjs

configure(allProjs) {
    apply plugin: 'application'
    apply plugin: 'java'
    apply plugin: 'scala'
    // apply plugin: 'findbugs'
    apply plugin: 'org.scoverage'
    apply plugin: 'scalaStyle'
    apply plugin: 'maven-publish'
    apply plugin: 'signing'
    apply plugin: 'project-report'
    apply plugin: 'com.commercehub.gradle.plugin.avro'
    apply plugin: 'net.minecrell.licenser'
    apply plugin: 'com.github.jk1.dependency-license-report'
    apply plugin: 'com.github.johnrengelman.shadow'

    sourceCompatibility = 1.8
    targetCompatibility = 1.8

    // Max: Set this to the main class for cli.
    // Could not figure out how to configure it just for the cli subproject
    mainClassName = "com.salesforce.op.cli.CLI"

    ext {
        scalaVersion = '2.11'
        scalaVersionRevision = '12'
        scalaTestVersion = '3.0.5'
        scalaCheckVersion = '1.14.0'
        junitVersion = '4.11'
        avroVersion = '1.7.7'
        sparkVersion = '2.2.1'
        sparkAvroVersion = '4.0.0'
        scalaGraphVersion = '1.12.5'
        scalafmtVersion = '1.5.1'
        hadoopVersion = 'hadoop2'
        scalajCollVersion = '0.1.2'
        json4sVersion = '3.2.11' // matches Spark dependency version
        jodaTimeVersion = '2.9.4'
        jodaConvertVersion = '1.8.1'
        algebirdVersion = '0.12.3'
        jacksonVersion = '2.7.3'
        luceneVersion = '7.3.0'
        enumeratumVersion = '1.4.12'
        scoptVersion = '3.5.0'
        googleLibPhoneNumberVersion = '8.8.5'
        googleGeoCoderVersion = '2.82'
        googleCarrierVersion = '1.72'
        chillAvroVersion = '0.8.0'
        reflectionsVersion = '0.9.11'
        collectionsVersion = '3.2.2'
        optimaizeLangDetectorVersion = '0.0.1'
        tikaVersion = '1.16'
        sparkTestingBaseVersion = '2.2.0_0.8.0'
        sourceCodeVersion = '0.1.3'
        pegdownVersion = '1.4.2'
        commonsValidatorVersion = '1.6'
        commonsIOVersion = '2.6'
        scoveragePluginVersion = '1.3.1'
        hadrianVersion = '0.8.5'
        aardpfarkVersion = '0.1.0-SNAPSHOT'

        mainClassName = 'com.salesforce.Main'
    }

    configurations {
        scalaLibrary
        scalaCompiler
    }

    dependencies {
        // Scala
        zinc 'com.typesafe.zinc:zinc:0.3.15'
        scoverage "org.scoverage:scalac-scoverage-plugin_$scalaVersion:$scoveragePluginVersion"
        scoverage "org.scoverage:scalac-scoverage-runtime_$scalaVersion:$scoveragePluginVersion"
        scalaLibrary "org.scala-lang:scala-library:$scalaVersion.$scalaVersionRevision"
        scalaCompiler "org.scala-lang:scala-compiler:$scalaVersion.$scalaVersionRevision"
        compile "org.scala-lang:scala-library:$scalaVersion.$scalaVersionRevision"

        // Spark
        compileOnly "org.apache.spark:spark-core_$scalaVersion:$sparkVersion"
        testCompile "org.apache.spark:spark-core_$scalaVersion:$sparkVersion"
        compileOnly "org.apache.spark:spark-mllib_$scalaVersion:$sparkVersion"
        testCompile "org.apache.spark:spark-mllib_$scalaVersion:$sparkVersion"
        compileOnly "org.apache.spark:spark-sql_$scalaVersion:$sparkVersion"
        testCompile "org.apache.spark:spark-sql_$scalaVersion:$sparkVersion"

        // Test
        compileOnly "org.scalatest:scalatest_$scalaVersion:$scalaTestVersion"
        testCompile "org.scalatest:scalatest_$scalaVersion:$scalaTestVersion"
        compileOnly "org.scalacheck:scalacheck_$scalaVersion:$scalaCheckVersion"
        testCompile "org.scoverage:scalac-scoverage-plugin_$scalaVersion:$scoveragePluginVersion"
        testCompile "org.scoverage:scalac-scoverage-runtime_$scalaVersion:$scoveragePluginVersion"
        testCompile "org.scalacheck:scalacheck_$scalaVersion:$scalaCheckVersion"
        testCompile ("com.holdenkarau:spark-testing-base_$scalaVersion:$sparkTestingBaseVersion") { transitive = false }
        testCompile "junit:junit:$junitVersion"
        testRuntime "org.pegdown:pegdown:$pegdownVersion"
    }

    configurations.all {
        resolutionStrategy {
            force "commons-collections:commons-collections:$collectionsVersion",
                    "org.scala-lang:scala-library:$scalaVersion.$scalaVersionRevision",
                    "org.scala-lang:scala-reflect:$scalaVersion.$scalaVersionRevision"
        }
    }
    configurations.zinc {
        resolutionStrategy {
            force 'org.scala-lang:scala-library:2.10.6', 'org.scala-lang:scala-reflect:2.10.6'
        }
    }

    tasks.withType(ScalaCompile) {
        configure(scalaCompileOptions.forkOptions) {
            memoryMaximumSize = '1g'
            jvmArgs = ['-XX:MaxMetaspaceSize=256m']
        }
        scalaCompileOptions.additionalParameters = [
                "-Yrangepos", "-feature",
                "-language:implicitConversions", "-language:existentials", "-language:postfixOps"
        ]
    }
    compileScala.scalaCompileOptions.additionalParameters += "-optimize"
    [compileJava, compileTestJava]*.options.collect { options -> options.encoding = 'UTF-8' }

    jar {
        manifest.attributes "Main-Class": "$mainClassName"
        baseName = "${rootProject.name}"
    }
    if (System.getenv("CI") != 'true') {
        jar.dependsOn(createVersionProperties)
    }

    scalaStyle {
        configLocation = "$rootProject.rootDir/gradle/scalastyle-config.xml"
        includeTestSourceDirectory = true
        source = "src/main/scala"
        testSource = "src/test/scala"
    }

    if (System.getenv("CI") != 'true') {
        compileScala.dependsOn(scalaStyle)
    }

    avro {
        createSetters = true
        fieldVisibility = "PUBLIC_DEPRECATED"
        outputCharacterEncoding = "UTF-8"
        stringType = "String"
    }

    sourceSets {
        main {
            java {
                srcDir 'build/generated-main-avro-java'
            }
        }
        scoverage {
            runtimeClasspath += sourceSets.main.output
            compileClasspath += sourceSets.main.output
        }
        testScoverage {
            runtimeClasspath += sourceSets.main.output + sourceSets.test.output
            compileClasspath += sourceSets.main.output + sourceSets.test.output
        }
    }

    license {
        header = rootProject.file('LICENSE')
        ignoreFailures = true
        include '**/*.java', '**/*.scala'
        exclude '**/org/apache/spark/ml/SparkDefaultParamsReadWrite.scala',
                '**/com/salesforce/op/test/TestSparkContext.scala',
                '**/com/salesforce/op/test/TempDirectoryTest.scala',
                '**/com/salesforce/op/stages/impl/tuning/OpCrossValidation.scala',
                '**/com/salesforce/op/stages/impl/tuning/OpTrainValidationSplit.scala',
                '**/com/salesforce/op/test/*.java',
                '**/com/fasterxml/jackson/module/scala/**',
                '**/templates/**', '**/resources/**'
    }
    scoverage {
        coverageOutputCobertura = false
    }

    licenseReport {
        renderer = new com.github.jk1.license.render.MultiReportRenderer(
                new com.github.jk1.license.render.CsvReportRenderer(),
                new com.github.jk1.license.render.InventoryHtmlReportRenderer()
        )
    }

    shadowJar {
        zip64 = true
        exclude 'META-INF/maven/**'
        baseName = jar.baseName
    }
    shadowJar.dependsOn(createVersionProperties)

    /* findbugs {
        toolVersion = '3.0.1'
        sourceSets = [sourceSets.main]
        ignoreFailures = true
        reportsDir = file("$project.buildDir/reports/findbugs")
        effort = 'max'
        reportLevel = 'low'
        includeFilter = file("$rootProject.projectDir/gradle/findbugs-include.xml")
        excludeFilter = file("$rootProject.projectDir/gradle/findbugs-exclude.xml")
    } */

    task runMain(type: JavaExec) {
        description 'Run a main class, i.e.: runMain -Dmain=MyMainClass -Dargs="arg1 arg2 arg3"'
        main = System.getProperty("main")
        classpath = sourceSets.main.runtimeClasspath
        systemProperties = System.getProperties()
        args = System.getProperty("args", "") == "" ? new LinkedList<String>() : Arrays.asList(System.getProperty("args").split(" "))
    }

    task repl(type: JavaExec) {
        description 'Start Scala repl.'
        main = "scala.tools.nsc.MainGenericRunner"
        classpath = sourceSets.main.runtimeClasspath + configurations.scalaCompiler
        standardInput System.in
        args '-usejavacp'
    }

    task classpath {
        doLast {
            description 'Print project classpath.'
            println sourceSets.main.runtimeClasspath.asPath
        }
    }

    if (System.getenv("TEST_FILES") != null) {
        testScoverage.setIncludes(Arrays.asList(System.getenv("TEST_FILES").split('\n')))
    }
}

wrapper {
    gradleVersion = '4.10.2'
    distributionType = Wrapper.DistributionType.BIN
    distributionSha256Sum = 'b49c6da1b2cb67a0caf6c7480630b51c70a11ca2016ff2f555eaeda863143a29'
}

task aggregateScoverage(type: org.scoverage.ScoverageAggregate) {
    description 'Aggregates scoverage reports of all subprojects.'
}

configure(subProjs) {
    apply from: "$rootProject.projectDir/gradle/tests.gradle"
    apply from: "$rootProject.projectDir/gradle/spark.gradle"

    jar.baseName = "$rootProject.name-$project.name"

    // ignore link warning in scaladoc
    scaladoc.scalaDocOptions.additionalParameters = ['-no-link-warnings']

    task scaladocJar(type: Jar, dependsOn: scaladoc) {
        classifier = 'javadoc'
        from scaladoc.destinationDir
    }
    scaladocJar.baseName = jar.baseName

    task sourcesJar(type: Jar, dependsOn: classes) {
        classifier = 'sources'
        from sourceSets.main.allSource
    }
    sourcesJar.baseName = jar.baseName

    artifacts {
        archives jar, sourcesJar, scaladocJar
    }

    publishing {
        publications {
            mavenJava(MavenPublication) {
                from components.java
                artifact sourcesJar { classifier 'sources' }
                artifact scaladocJar { classifier 'javadoc' }
                afterEvaluate {
                    artifactId = "${jar.baseName}_$scalaVersion"
                }
                pom {
                    name = 'TransmogrifAI'
                    description = 'AutoML library for building modular, reusable, strongly typed machine learning workflows on Spark with minimal hand tuning'
                    url = 'https://github.com/salesforce/TransmogrifAI'
                    scm {
                        connection = 'scm:git:https://github.com/salesforce/TransmogrifAI.git'
                        developerConnection = 'scm:git:https://github.com/salesforce/TransmogrifAI.git'
                        url = 'https://github.com/salesforce/TransmogrifAI'
                    }
                    licenses {
                        license {
                            name = 'BSD-3-Clause'
                            url = 'https://github.com/salesforce/TransmogrifAI/blob/master/LICENSE'
                            distribution = 'repo'
                        }
                    }
                    developers {
                        developer {
                            id = 'tovbinm'
                            name = 'Matthew Tovbin'
                            email = 'tovbinm@gmail.com'
                        }
                        developer {
                            id = 'leahmcguire'
                            name = 'Leah McGuire'
                            email = 'lmcguire@salesforce.com'
                        }
                    }
                }
            }
        }
        repositories {
            // Disable Sonatype publication for now
            // maven {
            //     // Note: requires 'nexusUsername' and 'nexusPassword' to be set in ~/.gradle/gradle.properties file
            //     url "https://oss.sonatype.org/service/local/staging/deploy/maven2"
            //     credentials {
            //         username nexusUsername
            //         password nexusPassword
            //     }
            // }
            // Disable Bintray publication for now
            // maven {
            //     // Note: requires 'bintrayUsername' and 'bintrayPassword' to be set in ~/.gradle/gradle.properties file
            //     url "https://api.bintray.com/maven/salesforce/maven/TransmogrifAI/;publish=1"
            //     credentials {
            //         username bintrayUsername
            //         password bintrayPassword
            //     }
            // }
        }
    }

    if (System.getenv("SIGN_RELEASE") == 'true') {
        signing {
            // Note: requires 'signing.keyId', 'signing.password', 'signing.secretKeyRingFile' be set in ~/.gradle/gradle.properties file
            // and https://gpgtools.org/ (gpg2 installed and configured)
            useGpgCmd()
            sign publishing.publications.mavenJava
        }
    }
}

task allScaladoc(type: ScalaDoc) {
    group 'Documentation'
    description 'Generates Scaladoc for the main source code of all subprojects.'
    title 'TransmogrifAI'
    source subProjs.collect { it.sourceSets.main.allJava + it.sourceSets.main.allScala }
    classpath = files(subProjs.collect { it.sourceSets.main.compileClasspath })
    destinationDir = file("build/scaladoc")
}

// run by Heroku to build docs
task stage(dependsOn: ':allScaladoc')
